{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "considerable-receipt",
   "metadata": {},
   "source": [
    "## import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "right-juice",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In C:\\ProgramData\\Miniconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\ProgramData\\Miniconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\ProgramData\\Miniconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In C:\\ProgramData\\Miniconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\ProgramData\\Miniconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\ProgramData\\Miniconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\ProgramData\\Miniconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\ProgramData\\Miniconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as spio\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "from scipy.ndimage.filters import gaussian_filter1d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improved-numbers",
   "metadata": {},
   "source": [
    "## Util functions to calculate ISI violations, firing rate, presence ration, ampltide cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "floating-evidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_isi_violations(spike_times, spike_clusters, total_units, isi_threshold, min_isi):\n",
    "    cluster_ids = np.unique(spike_clusters)\n",
    "    viol_rates = np.zeros((total_units,))\n",
    "    for idx, cluster_id in enumerate(cluster_ids):\n",
    "        for_this_cluster = (spike_clusters == cluster_id)\n",
    "        viol_rates[idx], num_violations = isi_violations(spike_times[for_this_cluster],\n",
    "                                                       min_time = np.min(spike_times[for_this_cluster]),\n",
    "                                                       max_time = np.max(spike_times[for_this_cluster]),\n",
    "                                                       isi_threshold=isi_threshold,\n",
    "                                                       min_isi = min_isi)\n",
    "    return viol_rates\n",
    "\n",
    "\n",
    "def calculate_firing_rate(spike_times, spike_clusters, total_units):\n",
    "    cluster_ids = np.unique(spike_clusters)\n",
    "    firing_rates = np.zeros((total_units,))\n",
    "    min_time = np.min(spike_times)\n",
    "    max_time = np.max(spike_times)\n",
    "    for idx, cluster_id in enumerate(cluster_ids):\n",
    "        for_this_cluster = (spike_clusters == cluster_id)\n",
    "        firing_rates[idx] = firing_rate(spike_times[for_this_cluster],\n",
    "                                        min_time = np.min(spike_times),\n",
    "                                        max_time = np.max(spike_times))\n",
    "    return firing_rates\n",
    "\n",
    "\n",
    "def calculate_presence_ratio(spike_times, spike_clusters, total_units):\n",
    "    cluster_ids = np.unique(spike_clusters)\n",
    "    ratios = np.zeros((total_units,))\n",
    "    for idx, cluster_id in enumerate(cluster_ids):\n",
    "        for_this_cluster = (spike_clusters == cluster_id)\n",
    "        ratios[idx] = presence_ratio(spike_times[for_this_cluster],\n",
    "                                                       min_time = np.min(spike_times),\n",
    "                                                       max_time = np.max(spike_times))\n",
    "    return ratios\n",
    "\n",
    "\n",
    "def calculate_amplitude_cutoff(spike_clusters, amplitudes, total_units):\n",
    "    cluster_ids = np.unique(spike_clusters)\n",
    "    amplitude_cutoffs = np.zeros((total_units,))\n",
    "    for idx, cluster_id in enumerate(cluster_ids):\n",
    "        for_this_cluster = (spike_clusters == cluster_id)\n",
    "        amplitude_cutoffs[idx] = amplitude_cutoff(amplitudes[for_this_cluster])\n",
    "    return amplitude_cutoffs\n",
    "\n",
    "\n",
    "def isi_violations(spike_train, min_time, max_time, isi_threshold, min_isi=0):\n",
    "    \"\"\"Calculate ISI violations for a spike train.\n",
    "    Based on metric described in Hill et al. (2011) J Neurosci 31: 8699-8705\n",
    "    modified by Dan Denman from cortex-lab/sortingQuality GitHub by Nick Steinmetz\n",
    "    Inputs:\n",
    "    -------\n",
    "    spike_train : array of spike times\n",
    "    min_time : minimum time for potential spikes\n",
    "    max_time : maximum time for potential spikes\n",
    "    isi_threshold : threshold for isi violation\n",
    "    min_isi : threshold for duplicate spikes\n",
    "    Outputs:\n",
    "    --------\n",
    "    fpRate : rate of contaminating spikes as a fraction of overall rate\n",
    "        A perfect unit has a fpRate = 0\n",
    "        A unit with some contamination has a fpRate < 0.5\n",
    "        A unit with lots of contamination has a fpRate > 1.0\n",
    "    num_violations : total number of violations\n",
    "    \"\"\"\n",
    "\n",
    "    duplicate_spikes = np.where(np.diff(spike_train) <= min_isi)[0]\n",
    "\n",
    "    spike_train = np.delete(spike_train, duplicate_spikes + 1)\n",
    "    isis = np.diff(spike_train)\n",
    "\n",
    "    num_spikes = len(spike_train)\n",
    "    num_violations = sum(isis < isi_threshold)\n",
    "    violation_time = 2*num_spikes*(isi_threshold - min_isi)\n",
    "    total_rate = firing_rate(spike_train, min_time, max_time)\n",
    "    violation_rate = num_violations/violation_time\n",
    "    fpRate = violation_rate/total_rate\n",
    "    return fpRate, num_violations\n",
    "\n",
    "\n",
    "def firing_rate(spike_train, min_time = None, max_time = None):\n",
    "    \"\"\"Calculate firing rate for a spike train.\n",
    "    If no temporal bounds are specified, the first and last spike time are used.\n",
    "    Inputs:\n",
    "    -------\n",
    "    spike_train : numpy.ndarray\n",
    "        Array of spike times in seconds\n",
    "    min_time : float\n",
    "        Time of first possible spike (optional)\n",
    "    max_time : float\n",
    "        Time of last possible spike (optional)\n",
    "    Outputs:\n",
    "    --------\n",
    "    fr : float\n",
    "        Firing rate in Hz\n",
    "    \"\"\"\n",
    "    if min_time is not None and max_time is not None:\n",
    "        duration = max_time - min_time\n",
    "    else:\n",
    "        duration = np.max(spike_train) - np.min(spike_train)\n",
    "    fr = spike_train.size / duration\n",
    "    return fr\n",
    "\n",
    "\n",
    "def presence_ratio(spike_train, min_time, max_time, num_bins=100):\n",
    "    \"\"\"Calculate fraction of time the unit is present within an epoch.\n",
    "    Inputs:\n",
    "    -------\n",
    "    spike_train : array of spike times\n",
    "    min_time : minimum time for potential spikes\n",
    "    max_time : maximum time for potential spikes\n",
    "    Outputs:\n",
    "    --------\n",
    "    presence_ratio : fraction of time bins in which this unit is spiking\n",
    "    \"\"\"\n",
    "    h, b = np.histogram(spike_train, np.linspace(min_time, max_time, num_bins))\n",
    "    return np.sum(h > 0) / num_bins\n",
    "\n",
    "\n",
    "def amplitude_cutoff(amplitudes, num_histogram_bins = 500, histogram_smoothing_value = 3):\n",
    "    \"\"\" Calculate approximate fraction of spikes missing from a distribution of amplitudes\n",
    "    Assumes the amplitude histogram is symmetric (not valid in the presence of drift)\n",
    "    Inspired by metric described in Hill et al. (2011) J Neurosci 31: 8699-8705\n",
    "    Input:\n",
    "    ------\n",
    "    amplitudes : numpy.ndarray\n",
    "        Array of amplitudes (don't need to be in physical units)\n",
    "    Output:\n",
    "    -------\n",
    "    fraction_missing : float\n",
    "        Fraction of missing spikes (0-0.5)\n",
    "        If more than 50% of spikes are missing, an accurate estimate isn't possible\n",
    "    \"\"\"\n",
    "    h,b = np.histogram(amplitudes, num_histogram_bins, density=True)\n",
    "    pdf = gaussian_filter1d(h,histogram_smoothing_value)\n",
    "    support = b[:-1]\n",
    "    peak_index = np.argmax(pdf)\n",
    "    G = np.argmin(np.abs(pdf[peak_index:] - pdf[0])) + peak_index\n",
    "    bin_size = np.mean(np.diff(support))\n",
    "    fraction_missing = np.sum(pdf[G:])*bin_size\n",
    "    fraction_missing = np.min([fraction_missing, 0.5])\n",
    "    return fraction_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "educated-chicago",
   "metadata": {},
   "source": [
    "## cutoff threshold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "synthetic-monkey",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "params['isi_threshold']=0.0015\n",
    "params['min_isi']=0.00\n",
    "params['isi_viol_th']=0.2 #20% violations\n",
    "params['presence_ratio']=0.4\n",
    "params['firing_rate_th']=0.5 #0.5Hz\n",
    "params['amp_cutoff_th']=0.01\n",
    "params['amp_th']=25 #25uV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "refined-process",
   "metadata": {},
   "source": [
    "## load the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "therapeutic-career",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 30000.0\n",
    "spike_times = np.ravel(np.load('spike_times.npy', allow_pickle=True))/fs\n",
    "spike_clusters = np.ravel(np.load('spike_clusters.npy', allow_pickle=True))\n",
    "spike_templates = np.ravel(np.load('spike_templates.npy', allow_pickle=True))\n",
    "amplitudes = np.ravel(np.load('amplitudes.npy', allow_pickle=True))\n",
    "templates = np.load('templates.npy')\n",
    "channel_map = np.load('channel_map.npy')[0]\n",
    "cluster_info = pd.read_csv('cluster_info.tsv', sep='\\t')\n",
    "total_units = len(np.unique(spike_clusters))\n",
    "epoch = [1000, np.inf]\n",
    "if epoch[0]==np.inf:\n",
    "    in_epoch = (spike_times <= epoch[-1])\n",
    "elif epoch[-1]==np.inf:\n",
    "    in_epoch = (spike_times >= epoch[0])\n",
    "else:\n",
    "    in_epoch = (spike_times > epoch[0]) * (spike_times < epoch[-1])\n",
    "metrics = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simple-accessory",
   "metadata": {},
   "source": [
    "# Calculate unit quality metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "sporting-broadcasting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating isi violations\n"
     ]
    }
   ],
   "source": [
    "print(\"Calculating isi violations\")\n",
    "isi_viol = calculate_isi_violations(spike_times[in_epoch], spike_clusters[in_epoch], total_units, params['isi_threshold'], params['min_isi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "treated-attempt",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating presence ratio\n"
     ]
    }
   ],
   "source": [
    "print(\"Calculating presence ratio\")\n",
    "presence_ratio = calculate_presence_ratio(spike_times[in_epoch], spike_clusters[in_epoch], total_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "agreed-immigration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating firing rate\n"
     ]
    }
   ],
   "source": [
    "print(\"Calculating firing rate\")\n",
    "firing_rate = calculate_firing_rate(spike_times[in_epoch], spike_clusters[in_epoch], total_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "direct-throat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating amplitude cutoff\n"
     ]
    }
   ],
   "source": [
    "print(\"Calculating amplitude cutoff\")\n",
    "amplitude_cutoff = calculate_amplitude_cutoff(spike_clusters[in_epoch], amplitudes[in_epoch], total_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "regular-ground",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_ids = np.unique(spike_clusters)\n",
    "epoch_name = ['Experiment'] * len(cluster_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "insured-absence",
   "metadata": {},
   "source": [
    "## finalize the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "announced-controversy",
   "metadata": {},
   "outputs": [],
   "source": [
    " metrics = pd.concat((metrics, pd.DataFrame(data= OrderedDict((('cluster_id', cluster_ids),\n",
    "                                ('firing_rate' , firing_rate),\n",
    "                                ('presence_ratio' , presence_ratio),\n",
    "                                ('isi_viol' , isi_viol),\n",
    "                                ('amp_cutoff' , amplitude_cutoff),\n",
    "                                ('epoch_name' , epoch_name),\n",
    "                                )))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "excess-nutrition",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics['group'] = cluster_info['group']\n",
    "metrics['depth'] = cluster_info['depth']\n",
    "metrics['ch'] = cluster_info['ch']\n",
    "metrics['num_spikes'] = cluster_info['n_spikes']\n",
    "metrics['amp'] = cluster_info['amp']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "better-programmer",
   "metadata": {},
   "source": [
    "## find good cell based on cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fallen-samoa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121\n"
     ]
    }
   ],
   "source": [
    "isGoodCell = (metrics['isi_viol']<params['isi_viol_th']) & (metrics['amp_cutoff']<params['amp_cutoff_th']) & (metrics['amp']>params['amp_th']) & (metrics['presence_ratio']>params['presence_ratio']) & (metrics['firing_rate']>params['firing_rate_th']) & (metrics['group']=='good')\n",
    "metrics['isGood'] = isGoodCell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "favorite-degree",
   "metadata": {},
   "source": [
    "## save the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adapted-company",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = os.path.join(os.getcwd(),'UnitMetrics.csv')\n",
    "metrics.to_csv(fname, index= True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
